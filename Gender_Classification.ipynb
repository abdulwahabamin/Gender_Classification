{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Data and corresponding labels\n",
    "# [height, weight, shoe_size]\n",
    "X = [[181, 80, 44], [177, 70, 43], [160, 60, 38], [154, 54, 37], [166, 65, 40],\n",
    "     [190, 90, 47], [175, 64, 39],\n",
    "     [177, 70, 40], [159, 55, 37], [171, 75, 42], [181, 85, 43]]\n",
    "\n",
    "Y = ['male', 'male', 'female', 'female', 'male', 'male', 'female', 'female',\n",
    "     'female', 'male', 'male']\n",
    "\n",
    "test_data = [[190, 70, 43],[154, 75, 42],[181,65,40]]\n",
    "test_labels = ['male','male','male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'male' 'female']\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "prediction = clf.predict(test_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'male' 'female']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "r_clf = RandomForestClassifier()\n",
    "r_clf.fit(X,Y)\n",
    "r_prediction = clf.predict(test_data)\n",
    "print(r_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male' 'female']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "l_clf = LogisticRegression()\n",
    "l_clf.fit(X,Y)\n",
    "l_prediction = l_clf.predict(test_data)\n",
    "print(l_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'male' 'male']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Classifier\n",
    "s_clf = SVC()\n",
    "s_clf.fit(X,Y)\n",
    "s_prediction = s_clf.predict(test_data)\n",
    "print(s_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC is the best classifier for this problem\n"
     ]
    }
   ],
   "source": [
    "#Comparing accuracy of different classifiers\n",
    "\n",
    "classifiers = ['Decision Tree', 'Random Forest', 'Logistic Regression' , 'SVC']\n",
    "#Decision Tree\n",
    "d_tree_acc = accuracy_score(prediction,test_labels)\n",
    "#Random Forest\n",
    "random_acc = accuracy_score(r_prediction,test_labels)\n",
    "#logistic Regression\n",
    "logistic_acc = accuracy_score(l_prediction,test_labels)\n",
    "#SVC\n",
    "support_acc = accuracy_score(s_prediction,test_labels)\n",
    "\n",
    "accuracy = np.array([d_tree_acc, random_acc, logistic_acc, support_acc])\n",
    "max_acc = np.argmax(accuracy)\n",
    "print(classifiers[max_acc] + ' is the best classifier for this problem')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
